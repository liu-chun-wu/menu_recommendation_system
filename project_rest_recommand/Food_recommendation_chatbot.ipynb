{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "be68iGaxWJ3V"
      },
      "source": [
        "# Import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "0Y3OiA2vTkZ-"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import requests\n",
        "from typing import List\n",
        "\n",
        "import chromadb\n",
        "from chromadb.api.types import Documents, Embeddings\n",
        "from chromadb.utils.embedding_functions import EmbeddingFunction\n",
        "\n",
        "import google.generativeai as genai\n",
        "\n",
        "import gradio as gr\n",
        "import fitz  # è¦å®‰è£PyMuPDF"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ATPAganzwKjS"
      },
      "source": [
        "# Download PDF and Extract text from PDF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "dnd8o8dJWwfh"
      },
      "outputs": [],
      "source": [
        "def download_pdf(url, save_path):\n",
        "    \"\"\"\n",
        "    å¾æŒ‡å®š URL ä¸‹è¼‰ PDF æ–‡ä»¶ä¸¦å„²å­˜åˆ°æœ¬åœ°ã€‚\n",
        "\n",
        "    :param url: PDF æ–‡ä»¶çš„ç¶²å€ (string)\n",
        "    :param save_path: PDF æ–‡ä»¶å„²å­˜çš„æœ¬åœ°è·¯å¾‘ (string)\n",
        "    \"\"\"\n",
        "    # ä½¿ç”¨ requests æ¨¡çµ„ç™¼é€ HTTP GET è«‹æ±‚ä»¥ç²å– PDF æ–‡ä»¶\n",
        "    response = requests.get(url)\n",
        "\n",
        "    # æ‰“é–‹æŒ‡å®šçš„æœ¬åœ°å„²å­˜è·¯å¾‘ï¼Œä½¿ç”¨äºŒé€²ä½å¯«å…¥æ¨¡å¼ ('wb')\n",
        "    with open(save_path, 'wb') as f:\n",
        "        # å°‡ä¸‹è¼‰çš„æ–‡ä»¶å…§å®¹å¯«å…¥åˆ°æœ¬åœ°æ–‡ä»¶ä¸­\n",
        "        f.write(response.content)\n",
        "\n",
        "\n",
        "def extract_text_from_pdf_file_obj(file):\n",
        "    \"\"\"\n",
        "    å¾ PDF æª”æ¡ˆç‰©ä»¶æå–æ–‡æœ¬å…§å®¹ã€‚\n",
        "\n",
        "    :param file: PDF æ–‡ä»¶çš„æª”æ¡ˆç‰©ä»¶ (e.g., é€šé open(file, 'rb') ç²å–)\n",
        "    :return: æå–çš„æ–‡æœ¬å…§å®¹ (string)\n",
        "    \"\"\"\n",
        "    try:\n",
        "        with fitz.open(file.name) as doc:\n",
        "            pdf_text = \"\"\n",
        "            for page in doc:\n",
        "                pdf_text += page.get_text()\n",
        "        return pdf_text\n",
        "    except Exception as e:\n",
        "        return f\"Error while reading PDF: {str(e)}\"\n",
        "\n",
        "\n",
        "def extract_text_from_pdf_file_path(file_path):\n",
        "    \"\"\"\n",
        "    å¾ PDF æ–‡ä»¶çš„è·¯å¾‘æå–æ–‡æœ¬å…§å®¹ã€‚\n",
        "\n",
        "    :param file_path: PDF æ–‡ä»¶çš„æª”æ¡ˆè·¯å¾‘ (string)\n",
        "    :return: æå–çš„æ–‡æœ¬å…§å®¹ (string)\n",
        "    \"\"\"\n",
        "    try:\n",
        "        with fitz.open(file_path) as doc:\n",
        "            pdf_text = \"\"\n",
        "            for page in doc:\n",
        "                pdf_text += page.get_text()\n",
        "        return pdf_text\n",
        "    except Exception as e:\n",
        "        return f\"Error while reading PDF: {str(e)}\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DF0z6jspWTyF"
      },
      "source": [
        "# ToDo:\n",
        "- Text splitting\n",
        "- ChromaDB\n",
        "- Prompt Construction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A5bU0WilGZca"
      },
      "source": [
        "## Implement text splitting function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "GrW4ejl4Fm5u"
      },
      "outputs": [],
      "source": [
        "# åˆ†å‰²æ–‡æœ¬ç‚ºå°å¡Š\n",
        "def split_text(text: str, max_chunk_size: int = 500, overlap: int = 50) -> List[str]:\n",
        "    \"\"\"\n",
        "    å°‡é•·æ–‡æœ¬åˆ†å‰²ç‚ºå¤šå€‹å°å¡Šï¼Œæ”¯æ´å¡Šä¹‹é–“çš„é‡ç–Šã€‚\n",
        "\n",
        "    :param text: è¦åˆ†å‰²çš„æ–‡æœ¬ (string)\n",
        "    :param max_chunk_size: æ¯å€‹æ–‡æœ¬å¡Šçš„æœ€å¤§å¤§å° (int)\n",
        "    :param overlap: æ¯å€‹æ–‡æœ¬å¡Šä¹‹é–“çš„é‡ç–Šå¤§å° (int)\n",
        "    :return: åˆ†å‰²å¾Œçš„æ–‡æœ¬å¡Šåˆ—è¡¨ (List of strings)\n",
        "    \"\"\"\n",
        "    chunks = []\n",
        "    start = 0\n",
        "    while start < len(text):\n",
        "        end = min(start + max_chunk_size, len(text))\n",
        "        chunks.append(text[start:end].strip())\n",
        "        start += max_chunk_size - overlap\n",
        "    return chunks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pxb_4mmFGg-h"
      },
      "source": [
        "## Custom embedding function using Gemini API"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "qZqtNV_nFy-M"
      },
      "outputs": [],
      "source": [
        "# è‡ªå®šç¾© Gemini åµŒå…¥å‡½æ•¸\n",
        "class GeminiEmbeddingFunction(EmbeddingFunction):\n",
        "    def __init__(self, api_key: str, model: str = \"models/embedding-001\", title: str = \"Custom query\"):\n",
        "        self.api_key = api_key\n",
        "        self.model = model\n",
        "        self.title = title\n",
        "        genai.configure(api_key=self.api_key)\n",
        "\n",
        "    def __call__(self, input: Documents) -> Embeddings:\n",
        "        return [\n",
        "            genai.embed_content(\n",
        "                model=self.model,\n",
        "                content=doc,\n",
        "                task_type=\"retrieval_document\",\n",
        "                title=self.title\n",
        "            )[\"embedding\"]\n",
        "            for doc in input\n",
        "        ]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qi9IA2FiGmwk"
      },
      "source": [
        "## Implement ChromaDB creation and querying"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "75pEi_qbWwfj"
      },
      "outputs": [],
      "source": [
        "# å‘ç¾æœ‰çš„ ChromaDB é›†åˆä¸­æ–°å¢æ–‡ä»¶ã€‚\n",
        "def update_chroma_db(client, collection_name: str, new_documents: List[str]):\n",
        "    \"\"\"\n",
        "    å‘ç¾æœ‰çš„ ChromaDB é›†åˆä¸­æ–°å¢æ–‡ä»¶ã€‚\n",
        "\n",
        "    :param path: ChromaDB çš„è³‡æ–™åº«è·¯å¾‘ (string)\n",
        "    :param collection_name: è¦æ›´æ–°çš„é›†åˆåç¨± (string)\n",
        "    :param new_documents: è¦æ–°å¢çš„æ–‡ä»¶åˆ—è¡¨ (List of strings)\n",
        "    \"\"\"\n",
        "\n",
        "    # Get the existing collection by name\n",
        "    collection = client.get_or_create_collection(collection_name)\n",
        "\n",
        "    # Add new documents to the collection\n",
        "    for i, document in enumerate(new_documents):\n",
        "        collection.add(\n",
        "            ids=[f\"new_doc_{i}\"],  # New unique ID for each document\n",
        "            documents=[document],  # New document content\n",
        "        )\n",
        "\n",
        "    print(f\"Added {len(new_documents)} new documents to the collection '{collection_name}'.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "bqBRdBb10CB6"
      },
      "outputs": [],
      "source": [
        "# æŸ¥è©¢ç›¸é—œæ®µè½\n",
        "def get_relevant_passage(query: str, db, name: str, n_results: int = 3) -> List[str]:\n",
        "    \"\"\"\n",
        "    å¾æŒ‡å®šçš„ ChromaDB é›†åˆä¸­æŸ¥è©¢èˆ‡çµ¦å®šå•é¡Œç›¸é—œçš„æ®µè½ã€‚\n",
        "\n",
        "    :param query: ç”¨æˆ¶çš„æŸ¥è©¢èªå¥ (string)\n",
        "    :param db: é€£æ¥çš„ ChromaDB è³‡æ–™åº«å°è±¡\n",
        "    :param name: è¦æŸ¥è©¢çš„é›†åˆåç¨± (string)\n",
        "    :param n_results: è¿”å›çš„ç›¸é—œçµæœæ•¸é‡ (int, é»˜èªç‚º 3)\n",
        "    :ret\n",
        "    \"\"\"\n",
        "    collection = db.get_collection(name)\n",
        "    results = collection.query(query_texts=[query], n_results=n_results)\n",
        "    return results[\"documents\"][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "c6Mb0RSDGwRf"
      },
      "outputs": [],
      "source": [
        "# å»ºæ§‹æç¤ºè©\n",
        "def make_rag_prompt(query: str, relevant_passages: List[str]) -> str:\n",
        "    context = \"\\n\\n\".join(relevant_passages)\n",
        "    return f\"\"\"\n",
        "    You are an intelligent assistant. Use the following context to answer the question:\n",
        "\n",
        "    Context:\n",
        "    {context}\n",
        "\n",
        "    Question:\n",
        "    {query}\n",
        "\n",
        "    Provide a concise and accurate response.\n",
        "    \"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YSO0EfflwBUa"
      },
      "source": [
        "# LLM Response Generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g0T1PfvaWwfk",
        "outputId": "66a01aa4-e3a5-40a0-a76f-17f8e30669f5"
      },
      "outputs": [],
      "source": [
        "# Check Gemini API key\n",
        "from dotenv import load_dotenv\n",
        "import os\n",
        "\n",
        "# è¼‰å…¥ .env æ–‡ä»¶ä¸­çš„æ‰€æœ‰è®Šæ•¸\n",
        "load_dotenv(\"key.env\")\n",
        "\n",
        "# ä½¿ç”¨ os.getenv ç²å–ç’°å¢ƒè®Šæ•¸\n",
        "api_key = os.getenv('Geminiapikey')\n",
        "\n",
        "\n",
        "# ç¢ºèªè®Šæ•¸æ˜¯å¦æ­£ç¢ºè¼‰å…¥\n",
        "print(f\"Gemini api key: {api_key}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "toYV28pPv_hj"
      },
      "outputs": [],
      "source": [
        "# Generate answer using Gemini Pro API\n",
        "def generate_answer(prompt: str):\n",
        "    load_dotenv()\n",
        "    api_key = os.getenv('Geminiapikey')\n",
        "    gemini_api_key = api_key\n",
        "    if not gemini_api_key:\n",
        "        raise ValueError(\n",
        "            \"Gemini API Key not provided. Please provide GEMINI_API_KEY as an environment variable\")\n",
        "    genai.configure(api_key=gemini_api_key)\n",
        "    model = genai.GenerativeModel('gemini-pro')\n",
        "    result = model.generate_content(prompt)\n",
        "    return result.text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3nDaJf9YWwfl"
      },
      "source": [
        "# Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7fyH03P_Wwfl",
        "outputId": "6f1d9da0-715c-4797-cf9b-db06c5aca7ea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "rag_experiment is created\n"
          ]
        }
      ],
      "source": [
        "# Set up configurations\n",
        "pdf_url = \"https://services.google.com/fh/files/misc/ai_adoption_framework_whitepaper.pdf\"\n",
        "pdf_path = \"ai_adoption_framework_whitepaper.pdf\"\n",
        "\n",
        "db_folder = \"chroma_db\"\n",
        "db_path = os.path.join(os.getcwd(), db_folder)\n",
        "\n",
        "# Create database directory\n",
        "if not os.path.exists(db_folder):\n",
        "    os.makedirs(db_folder)\n",
        "\n",
        "\n",
        "client = chromadb.PersistentClient(path=db_path)\n",
        "\n",
        "# a database unit in Chroma is called collection, so db here means collection\n",
        "db_name = \"rag_experiment\"\n",
        "client.get_or_create_collection(db_name)\n",
        "print(f\"{db_name} is created\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q5xwd91VWwfl",
        "outputId": "4fc5eb44-5ba9-418e-a660-00cd8e9d6b5b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/kd/.cache/chroma/onnx_models/all-MiniLM-L6-v2/onnx.tar.gz: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 79.3M/79.3M [02:34<00:00, 539kiB/s] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Added 129 new documents to the collection 'rag_experiment'.\n"
          ]
        }
      ],
      "source": [
        "# Download and process PDF\n",
        "download_pdf(pdf_url, pdf_path)\n",
        "pdf_text = extract_text_from_pdf_file_path(pdf_path)\n",
        "\n",
        "# Split text into chunks\n",
        "chunked_text = split_text(pdf_text)\n",
        "\n",
        "update_chroma_db(client, db_name, chunked_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "lI6r-xXzWwfl",
        "outputId": "61f55090-60f8-4504-fad5-de8b2ddde2ed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Generated Answer: This file discusses an organization's maturity in adopting and using artificial intelligence (AI) technologies, specifically in the areas of automation, tactical maturity, and use cases of AI within different industries.\n"
          ]
        }
      ],
      "source": [
        "# Process user query\n",
        "query = 'what is this file talking about?'\n",
        "relevant_text = get_relevant_passage(query, client, db_name, n_results=3)\n",
        "\n",
        "# Generate and display answer\n",
        "if relevant_text:\n",
        "    final_prompt = make_rag_prompt(query, \"\".join(relevant_text))\n",
        "    answer = generate_answer(final_prompt)\n",
        "    print(\"\\nGenerated Answer:\", answer)\n",
        "else:\n",
        "    print(\"No relevant information found for the given query.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uahs6MZoWwfl"
      },
      "source": [
        "# Combine Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "3COvG9ayWwfl"
      },
      "outputs": [],
      "source": [
        "# å¾ PDF æ–‡ä»¶æå–æ–‡æœ¬ï¼Œåˆ†å‰²æ–‡æœ¬ç‚ºå°å¡Šï¼Œä¸¦æ›´æ–° ChromaDB é›†åˆã€‚\n",
        "def add_document_to_db(client, db_name, file):\n",
        "    \"\"\"\n",
        "    :param db_path: ChromaDB è³‡æ–™åº«çš„è·¯å¾‘ (string)\n",
        "    :param db_name: è¦æ›´æ–°çš„ ChromaDB é›†åˆåç¨± (string)\n",
        "    :param file: PDF æ–‡ä»¶çš„äºŒé€²ä½æ–‡ä»¶å°è±¡ (BinaryIO)\n",
        "    \"\"\"\n",
        "    pdf_text = extract_text_from_pdf_file_obj(file)\n",
        "\n",
        "    # Split text into chunks\n",
        "    chunked_text = split_text(pdf_text)\n",
        "\n",
        "    update_chroma_db(client, db_name, chunked_text)\n",
        "\n",
        "    print(f\"{db_name} is updated\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "qpF17N1HWwfm"
      },
      "outputs": [],
      "source": [
        "# åŸºæ–¼ RAG (Retrieval-Augmented Generation) æµç¨‹ç”Ÿæˆå›ç­”ã€‚\n",
        "def rag_response(query, client, db_name):\n",
        "    \"\"\"\n",
        "    :param query: ç”¨æˆ¶çš„æŸ¥è©¢èªå¥ (string)\n",
        "    :param client: é€£æ¥çš„ ChromaDB è³‡æ–™åº«å®¢æˆ¶ç«¯\n",
        "    :param db_name: æŸ¥è©¢çš„é›†åˆåç¨± (string)\n",
        "    :return: ç”Ÿæˆçš„å›ç­”æˆ–éŒ¯èª¤ä¿¡æ¯ (string)\n",
        "    \"\"\"\n",
        "    # Process user query\n",
        "    relevant_text = get_relevant_passage(query, client, db_name, n_results=3)\n",
        "\n",
        "    # Generate and display answer\n",
        "    if relevant_text:\n",
        "        final_prompt = make_rag_prompt(query, \"\".join(relevant_text))\n",
        "        answer = generate_answer(final_prompt)\n",
        "        response = \"\\nGenerated Answer:\"+answer\n",
        "    else:\n",
        "        response = \"No relevant information found for the given query.\"\n",
        "\n",
        "    return response"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4LyBBDZfwlzl"
      },
      "source": [
        "# Main execution\n",
        "## ToDo:\n",
        " - Chat history\n",
        " - Multiple file injest"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JirE2HszWwfm"
      },
      "source": [
        "# Initilaize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "KhQLbvm4Wwfm"
      },
      "outputs": [],
      "source": [
        "# åˆå§‹åŒ– ChromaDB è³‡æ–™åº«ï¼Œå‰µå»ºè³‡æ–™åº«ç›®éŒ„ä¸¦è¨­ç½®é›†åˆã€‚\n",
        "def initialize_database(db_folder: str, db_name: str) -> chromadb.PersistentClient:\n",
        "    \"\"\"\n",
        "    :param db_folder: è³‡æ–™åº«æ–‡ä»¶å¤¾åç¨± (string)\n",
        "    :param db_name: è³‡æ–™åº«é›†åˆåç¨± (string)\n",
        "    :return: å·²åˆå§‹åŒ–çš„ ChromaDB å®¢æˆ¶ç«¯ (chromadb.PersistentClient)\n",
        "    \"\"\"\n",
        "    # ç²å–ç•¶å‰å·¥ä½œç›®éŒ„ï¼Œæ§‹å»ºå®Œæ•´çš„è³‡æ–™åº«è·¯å¾‘\n",
        "    db_path = os.path.join(os.getcwd(), db_folder)\n",
        "\n",
        "    # å¦‚æœè³‡æ–™åº«ç›®éŒ„ä¸å­˜åœ¨ï¼Œå‰‡å‰µå»ºè©²ç›®éŒ„\n",
        "    if not os.path.exists(db_folder):\n",
        "        os.makedirs(db_folder)\n",
        "\n",
        "    # å‰µå»ºä¸€å€‹ PersistentClient é€£æ¥åˆ°æŒ‡å®šçš„è³‡æ–™åº«è·¯å¾‘\n",
        "    client = chromadb.PersistentClient(path=db_path)\n",
        "\n",
        "    # åœ¨è³‡æ–™åº«ä¸­å‰µå»ºæˆ–ç²å–æŒ‡å®šåç¨±çš„é›†åˆ\n",
        "    client.get_or_create_collection(db_name)\n",
        "\n",
        "    # æ‰“å°æç¤ºä¿¡æ¯ï¼Œç¢ºèªé›†åˆå·²å‰µå»ºæˆ–å­˜åœ¨\n",
        "    print(f\"Collection '{db_name}' is initialized in {db_folder}.\")\n",
        "\n",
        "    # è¿”å›å·²åˆå§‹åŒ–çš„å®¢æˆ¶ç«¯å°è±¡\n",
        "    return client"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "61PrhwWAWwfm",
        "outputId": "0e475c58-8bce-4a32-ee61-e30b11b9b07b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collection 'rag_experiment' is initialized in chroma_db.\n",
            "<chromadb.api.client.Client object at 0x7fcbb2e9feb0>\n"
          ]
        }
      ],
      "source": [
        "db_folder = \"chroma_db\"\n",
        "db_name = \"rag_experiment\"\n",
        "\n",
        "client = initialize_database(db_folder, db_name)\n",
        "print(client)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hge6K8BxWwfm"
      },
      "source": [
        "# gradio UI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hnyvCnc5Wwfn",
        "outputId": "9c426c4a-6edd-4c96-f13a-af6a8cba7e4b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/kd/.local/lib/python3.10/site-packages/gradio/components/chatbot.py:284: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# åˆå§‹åŒ–èŠå¤©æ­·å²\n",
        "chat_history = []  # ç”¨æ–¼å­˜å„²ç”¨æˆ¶å’Œæ©Ÿå™¨äººä¹‹é–“çš„æ‰€æœ‰å°è©±\n",
        "\n",
        "# å®šç¾©ç”¨æˆ¶è¼¸å…¥çš„äº¤äº’é‚è¼¯\n",
        "\n",
        "\n",
        "def respond(input_text, history):\n",
        "    \"\"\"\n",
        "    è™•ç†ç”¨æˆ¶è¼¸å…¥ï¼Œç”Ÿæˆå›æ‡‰ä¸¦æ›´æ–°èŠå¤©æ­·å²ã€‚\n",
        "    Args:\n",
        "        input_text (str): ç”¨æˆ¶çš„è¼¸å…¥è¨Šæ¯ã€‚\n",
        "        history (list): èŠå¤©æ­·å²è¨˜éŒ„ã€‚\n",
        "    Returns:\n",
        "        tuple: æ¸…ç©ºçš„è¼¸å…¥æ¡†å’Œæ›´æ–°å¾Œçš„èŠå¤©æ­·å²ã€‚\n",
        "    \"\"\"\n",
        "    # ç¢ºä¿èŠå¤©æ­·å²åˆå§‹åŒ–ç‚ºç©ºåˆ—è¡¨\n",
        "    if history is None:\n",
        "        history = []\n",
        "\n",
        "    # ä½¿ç”¨ RAG æ¨¡å‹ç”Ÿæˆå›æ‡‰\n",
        "    bot_response = rag_response(input_text, client, db_name)\n",
        "\n",
        "    # å°‡ç”¨æˆ¶è¼¸å…¥å’Œæ©Ÿå™¨äººå›æ‡‰è¿½åŠ åˆ°æ­·å²è¨˜éŒ„\n",
        "    history.append([input_text, bot_response])  # æ¯æ¬¡å°è©±ç‚º [ç”¨æˆ¶è¨Šæ¯, æ©Ÿå™¨äººå›æ‡‰]\n",
        "\n",
        "    return \"\", history  # è¿”å›æ¸…ç©ºçš„è¼¸å…¥æ¡†å’Œæ–°çš„èŠå¤©æ­·å²\n",
        "\n",
        "# è™•ç† PDF æ–‡ä»¶ä¸Šå‚³çš„å‡½æ•¸\n",
        "\n",
        "\n",
        "def handle_pdf_upload(file):\n",
        "    \"\"\"\n",
        "    è™•ç†ç”¨æˆ¶ä¸Šå‚³çš„ PDF æ–‡ä»¶ã€‚\n",
        "    Args:\n",
        "        file (File): ä¸Šå‚³çš„æ–‡ä»¶å°è±¡ã€‚\n",
        "    Returns:\n",
        "        str: æ–‡ä»¶è™•ç†ç‹€æ…‹ä¿¡æ¯ã€‚\n",
        "    \"\"\"\n",
        "    if file is None:\n",
        "        return \"å°šæœªä¸Šå‚³æ–‡ä»¶ã€‚\"\n",
        "\n",
        "    # æª¢æŸ¥æ–‡ä»¶æ ¼å¼æ˜¯å¦ç‚º PDF\n",
        "    if not file.name.endswith(\".pdf\"):\n",
        "        return \"åƒ…æ”¯æŒä¸Šå‚³ PDF æ–‡ä»¶ï¼\"\n",
        "\n",
        "    # æ¨¡æ“¬å°‡æ–‡ä»¶æ·»åŠ åˆ°æ•¸æ“šåº«\n",
        "    add_document_to_db(client, db_name, file)\n",
        "    return f\"å·²ä¸Šå‚³æ–‡ä»¶ï¼š{file.name}\"\n",
        "\n",
        "\n",
        "# å®šç¾© Gradio æ¥å£\n",
        "with gr.Blocks(css=\"\"\"\n",
        "    @import url('https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css');\n",
        "    .container { max-width: 600px; margin: auto; background: white; padding: 20px; border-radius: 10px; }\n",
        "    .btn-primary { background-color: #007bff; border: none; padding: 10px; }\n",
        "    .btn-danger { background-color: #dc3545; border: none; padding: 10px; }\n",
        "\"\"\") as demo:\n",
        "    with gr.Column(elem_id=\"container\"):\n",
        "        gr.Markdown(\"<h2 class='text-primary text-center'>food recommendation chatbot</h2>\")\n",
        "        chatbot = gr.Chatbot()\n",
        "        user_input = gr.Textbox(placeholder=\"eg. what can I eat as a vegetarian\", label=\"input\")\n",
        "\n",
        "        with gr.Row():\n",
        "            send_btn = gr.Button(\"ğŸ• submit\", elem_classes=\"btn btn-primary\")\n",
        "            clear_btn = gr.Button(\"ğŸ—‘ delete\", elem_classes=\"btn btn-danger\")\n",
        "\n",
        "        file_upload = gr.File(label=\"ğŸ“‚ upload PDF\", file_types=[\".pdf\"])\n",
        "        file_status = gr.Textbox(label=\"status of file\", interactive=False)\n",
        "\n",
        "    file_upload.change(handle_pdf_upload, file_upload, file_status)\n",
        "    user_input.submit(respond, [user_input, chatbot], [user_input, chatbot])\n",
        "    send_btn.click(respond, [user_input, chatbot], [user_input, chatbot])\n",
        "    clear_btn.click(lambda: [], None, chatbot)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W_Hgi9xaWwfn",
        "outputId": "ef4f3f00-8345-4576-906d-733bd1b45b35"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Closing server running on port: 7860\n"
          ]
        }
      ],
      "source": [
        "# æ”¾é€™é‚Šæ˜¯å› ç‚ºlaunchæœƒå¾ˆé›£æŒ‰åˆ°æœ€ä¸‹é¢çš„block\n",
        "demo.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 611
        },
        "id": "iSBU0bkuWwfn",
        "outputId": "7e62e857-8bc1-4a72-dc98-39dac13ac437"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "* Running on local URL:  http://127.0.0.1:7860\n",
            "* Running on public URL: https://5a850bd9b2b8992b9d.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://5a850bd9b2b8992b9d.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": []
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "demo.launch(share=True)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
